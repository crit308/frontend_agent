# Whiteboard + AI Integration – Implementation Plan

## 1. Objective
Transform the current experience so that:
* Conversational text continues to appear as chat bubbles.
* Visual content generated by the assistant (diagrams, arrows, labels, etc.) is rendered **directly on the whiteboard canvas**, not embedded as images inside chat messages.

---

## 2. High-Level Architecture
1. **Dual-Pane Layout**
   * Left (or bottom) pane: existing chat thread.
   * Right (or main) pane: interactive whiteboard canvas.
   * A resize / collapse control lets users focus on either side.

2. **Single Source of Truth for Canvas State**
   * Wrap the drawing canvas inside a new `WhiteboardProvider` that exposes:
     * `whiteboardAPI` – imperative methods exposed by the canvas component.
     * A jotai/redux/ctx store that mirrors the canvas scene for React components that need read-only access (toolbar, stats, etc.).

3. **AI ↔ Canvas Bridge**
   * Chat messages may carry a **metadata blob** describing one or more *whiteboard actions*.
   * When such a message is rendered, the chat component dispatches the actions to `WhiteboardProvider`, which uses `whiteboardAPI` to mutate the scene.

4. **Action Schema**
   ```ts
   type WhiteboardAction =
     | { type: "ADD_ELEMENTS"; elements: CanvasElement[] }
     | { type: "UPDATE_ELEMENTS"; elements: Partial<CanvasElement>[] }
     | { type: "DELETE_ELEMENTS"; ids: string[] };

   interface CanvasElement {
     id: string;          // generated once, stable
     kind: "text" | "arrow" | "shape" | "image" | string;
     x: number;
     y: number;
     w?: number;
     h?: number;
     angle?: number;
     text?: string;
     // …additional properties as needed
     meta?: {
       source: "assistant" | "user";
     };
   }
   ```

---

## 3. Detailed Front-End Tasks

### 3.1 Layout & Provider
1. Create `WhiteboardProvider.tsx`:
   * Holds a `useRef` to the canvas component's API (exposed via `ref`).
   * Exposes a `dispatchWhiteboardAction(action)` method via React context.
   * Internally translates `WhiteboardAction` → calls to `whiteboardAPI` (e.g. `updateScene`).
2. Update the root layout component:
   * Import & mount `WhiteboardProvider` around the canvas pane.
   * Ensure existing chat components stay unaffected.

### 3.2 Chat ↔ Canvas Bridge
1. Extend the chat message model with an optional `whiteboardActions: WhiteboardAction[]` field.
2. In the chat bubble renderer:
   * After the message is mounted, check for this field.
   * If present, call `WhiteboardContext.dispatchWhiteboardAction` for each action.
3. Provide a subtle visual cue when the canvas updates (e.g. small pulse on the canvas border) so users link the message to the drawing.

### 3.3 Programmatic Element Creation
1. Implement helpers in `whiteboard/elementFactory.ts` that take a `CanvasElement` spec and return a valid element object accepted by the canvas API.
2. Ensure each generated element carries `meta.source = "assistant"` for attribution.
3. Batch operations: when adding multiple elements, wrap calls in a single `updateScene` (or equivalent) to minimise re-renders.

### 3.4 Undo / Redo Integration
1. The canvas component already maintains an internal history stack.
2. After invoking `whiteboardAPI.updateScene`, call `whiteboardAPI.history.commit()` (or similar) so the operation is undoable.
3. Optional: colour code the undo history items originating from the assistant for future UX enhancements.

### 3.5 Tagging & Selection Rules
* On pointer-over of an element with `meta.source === "assistant"`, show a tiny robot icon.
* Allow normal editing / deletion; no write-protection is required.

### 3.6 Real-Time Collaboration (Optional Phase)
1. If a realtime layer exists, broadcast `WhiteboardAction` payloads instead of raw element diffs – keeps protocol stable.
2. Upon reception, remote clients dispatch identical actions through their local provider (idempotent if actions carry deterministic `id`s).

### 3.7 Persistence & Replay
1. **Saving:** Include the latest serialized canvas scene in the conversation transcript.
2. **Loading:**
   * Rehydrate chat first.
   * Mount canvas, then call `whiteboardAPI.importScene(serializedScene)`.
3. Version old transcripts by embedding a `v` field in the scene JSON.

### 3.8 UI Polish
* Toolbar: hide advanced tools initially; leave Select, Hand, Undo, Redo.
* Theme: derive colours from global design-tokens to maintain brand consistency.
* Add a "Focus Board" shortcut (`Ctrl+Shift+B`) to swap chat & board panes.

---

## 4. Back-End Notes (for BE Team)
1. **Data Storage**
   * Add a `whiteboardScene` column (JSONB) to the conversation table.
   * Ensure it accepts up to ~2 MB (typical upper bound for large scenes).

2. **Endpoints**
   * `POST /conversations/:id/scene` – save (or overwrite) the current scene.
   * `GET  /conversations/:id/scene` – retrieve the scene for initial load.

3. **WebSocket Events (if collaboration is needed)**
   * `whiteboard:action` – payload `{ conversationId, senderId, action }`.
   * Server simply relays to other participants; no transformation required.

4. **Versioning / Migration**
   * Store a `sceneVersion` integer in the DB. Increment when breaking changes are deployed.

5. **Security**
   * Validate that the incoming JSON matches the `CanvasElement` schema (use Zod/JSON-schema).
   * Rate-limit `whiteboard:action` events to avoid flooding.

---

## 5. Testing Strategy
* **Unit tests**
  * ElementFactory – verifies that all fields are populated correctly.
  * Provider reducer – given an action, updates scene deterministically.
* **Integration tests**
  * Render a chat message containing actions; expect elements to appear on canvas.
  * Undo / redo after AI insert.
* **E2E (Playwright)**
  * Full user flow: ask assistant to "Draw a triangle", confirm canvas shows triangle, undo, redo.

---

## 6. Roll-Out Phases & Timeline
1. **Phase 0 (1 week)** – Embed read-only canvas, no AI interaction.
2. **Phase 1 (2 weeks)** – Support `ADD_ELEMENTS` actions (text + arrows).
3. **Phase 2 (2 weeks)** – Support `UPDATE_ELEMENTS` & `DELETE_ELEMENTS`; allow AI repositioning.
4. **Phase 3 (3 weeks, parallel)** – Real-time collaboration + backend relays.

---

## 7. Risks & Mitigations
| Risk | Mitigation |
|------|------------|
| Large payloads bloat DB | Compress JSONB column, archive old scenes |
| Users lose context between chat & canvas | Add subtle visual link (pulse / highlight) each time AI draws |
| Undo stack corruption | Wrap all dispatched actions in try/catch → rollback on error |
| Collaboration conflicts | Use element IDs and version nonce to reconcile on client |

---

## 8. Next Steps
1. **Front-end**: spike `WhiteboardProvider` + simple ADD_ELEMENTS demo.
2. **Back-end**: create new `whiteboardScene` column + CRUD endpoints.
3. **Product/Design**: approve layout wireframes & action visual cues.

> Once Phase 0 is merged behind a feature flag, we can progressively expose AI-generated drawings to beta users. 